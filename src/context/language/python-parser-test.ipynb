{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from python_parser import PythonParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ast\n",
      "import sys\n",
      "import json\n",
      "\n",
      "def node_to_enclosing_context(node):\n",
      "    \"\"\"\n",
      "    Converts a Python AST to enclosing context object.\n",
      "    \"\"\"\n",
      "\n",
      "    enclosing_context = {\n",
      "        \"line_start\": node.lineno,\n",
      "        \"line_end\": node.end_lineno\n",
      "    }\n",
      "\n",
      "    return enclosing_context\n",
      "\n",
      "\n",
      "class PythonParser:\n",
      "    def __init__(self):\n",
      "        self.largest_size = 0\n",
      "        self.largest_enclosing_context = None\n",
      "\n",
      "    def process_node(self, node, line_start, line_end):\n",
      "        \"\"\"\n",
      "        Process a node and check if it encloses the specified line range.\n",
      "        \"\"\"\n",
      "        # Check if the node has location attributes\n",
      "\n",
      "        start_line = node.lineno\n",
      "        end_line = getattr(node, \"end_lineno\", start_line)\n",
      "\n",
      "        # Check if the node's range encloses the target range\n",
      "        if start_line <= line_start and line_end <= end_line:\n",
      "            size = end_line - start_line\n",
      "            if size > self.largest_size:\n",
      "                self.largest_size = size\n",
      "                self.largest_enclosing_context = node\n",
      "\n",
      "    def find_enclosing_context(self, file_content, line_start, line_end):\n",
      "        \"\"\"\n",
      "        Finds the largest enclosing context for a given line range.\n",
      "        \"\"\"\n",
      "        # Parse the file content into an AST\n",
      "        tree = ast.parse(file_content)\n",
      "\n",
      "        # Traverse the AST and process nodes\n",
      "        for node in ast.walk(tree):\n",
      "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):  # Add other types if needed\n",
      "                self.process_node(node, line_start, line_end)\n",
      "\n",
      "        # Return the largest enclosing context as a dictionary for simplicity\n",
      "        if self.largest_enclosing_context:\n",
      "            return node_to_enclosing_context(self.largest_enclosing_context)\n",
      "        else:\n",
      "            return None\n",
      "\n",
      "    def dry_run(self, file_content):\n",
      "        \"\"\"\n",
      "        Validates whether the Python code is syntactically correct.\n",
      "        \"\"\"\n",
      "        try:\n",
      "            ast.parse(file_content)\n",
      "            return {\"valid\": True, \"error\": \"\"}\n",
      "        except SyntaxError as e:\n",
      "            return {\"valid\": False, \"error\": str(e)}\n",
      "\n",
      "if __name__==\"__main__\":\n",
      "    try:\n",
      "        parser = PythonParser()\n",
      "        file_content = sys.argv[1]\n",
      "        job = sys.argv[2]\n",
      "\n",
      "        if job == \"dry_run\":\n",
      "            output = parser.dry_run(file_content)\n",
      "            if not output:\n",
      "                print(\"FAIL\")\n",
      "            print(json.dumps(output))\n",
      "        elif job == \"enclosing_context\":\n",
      "            line_start = int(sys.argv[3])\n",
      "            line_end = int(sys.argv[4])\n",
      "            output = parser.find_enclosing_context(file_content, line_start, line_end)\n",
      "            if not output:\n",
      "                print(\"FAIL\")\n",
      "            print(json.dumps(output))\n",
      "        else:\n",
      "            print(json.dumps({\"Unknown job\"}))\n",
      "        \n",
      "    except Exception as e:\n",
      "        print(json.dumps({\n",
      "            \"error\": str(e),\n",
      "            \"argv\": sys.argv\n",
      "        }))\n",
      "        \n",
      "        sys.exit(1)\n"
     ]
    }
   ],
   "source": [
    "parser = PythonParser()\n",
    "\n",
    "file_path = \"python_parser.py\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    fileContents = f.read()\n",
    "\n",
    "print(fileContents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line_start': 18, 'line_end': 65}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.find_enclosing_context(fileContents, 41, 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line_start': 18, 'line_end': 67}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.find_enclosing_context(fileContents, 41, 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
